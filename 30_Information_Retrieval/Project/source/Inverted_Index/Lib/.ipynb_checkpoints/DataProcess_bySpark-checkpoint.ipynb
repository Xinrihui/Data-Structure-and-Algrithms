{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections import *\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"read_csv\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0\\x01 abc\\x02 \\\\\\x01 李超', '1\\x01 abc \\x03 \\x01 超哥 \\x02 \\x01 666 ', '2\\x01 abc \\x01   阿辉 \\x01 777 ']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data_test/'\n",
    "\n",
    "test_file_dir=os.path.join(data_dir, '20200614.csv')\n",
    "\n",
    "result_file_dir=os.path.join(data_dir, '20200614-result.csv')\n",
    "\n",
    "sliceNum=2\n",
    "lines = sc.textFile(test_file_dir,sliceNum) # 对大文件 进行切片 sliceNum=8，否则报错\n",
    "                                            # 20/05/30 11:54:28 ERROR PythonRunner: This may have been caused by a prior exception:\n",
    "                                            # java.net.SocketException: Connection reset by peer: socket write error\n",
    "\n",
    "print(lines.take(10))\n",
    "col_num=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 Map 函数 ，\n",
    "\n",
    "def process_oneline(line,col_num):\n",
    "    \n",
    "    line_array=line.split(\"\\x01\") # \"\\x01\" 为字节表示\n",
    "    length=len(line_array)\n",
    "    \n",
    "    line_array.append(length) \n",
    "    \n",
    "    res=None\n",
    "    \n",
    "    if length!=col_num : # 找到 字段数目 不符合 col_num 的\n",
    "        \n",
    "        res=line_array\n",
    "    \n",
    "    \n",
    "    return res # 每一行 必须都 要有 返回\n",
    "\n",
    "linesByMap=lines.map(lambda line :process_oneline(line ,col_num ))\n",
    "print(linesByMap.take(10)) # [None, ['1', ' abc \\x03 ', ' 超哥 ', ' 666 ', 4], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 mapPartitions\n",
    "# 找到 字段数目 不匹配的行 并输出 \n",
    "\n",
    "def process_oneslice(lines_slice,col_num):\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    for line in lines_slice:\n",
    "    \n",
    "        line_array=line.split(\"\\x01\")\n",
    "        \n",
    "        length=len(line_array)\n",
    "\n",
    "        line_array.append(length) # 记录 总的字段数目 \n",
    "\n",
    "        if length!=col_num : # 找到 字段数目 不符合 col_num 的\n",
    "          \n",
    "            res.append( line + str(line_array) )\n",
    "    \n",
    "    return res \n",
    "\n",
    "linesByMapPartitions=lines.mapPartitions(lambda lines_slice :process_oneslice(lines_slice ,col_num ))\n",
    "\n",
    "# print(linesByMapPartitions.take(10)) # \n",
    "\n",
    "# 分区合并 ，最后只写出 一个文件\n",
    "one_slice=linesByMapPartitions.coalesce(1, shuffle=True)\n",
    "\n",
    "one_slice.saveAsTextFile(result_file_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有 不可见的字符 写到 文本中\n",
    "\n",
    "data_dir = '../data_test/'\n",
    "test_file_dir = os.path.join(data_dir, 'all_invisible_characters.csv') #\n",
    "\n",
    "encoding='utf-8'\n",
    "\n",
    "control_chars = ''.join(map(chr, list(range(0,32)) + list(range(127,160)))) # 不可见字符的 范围 为 0-32 和 127-160  \n",
    "\n",
    "# control_chars=re.escape(control_chars) #对文本（字符串）中所有可能被解释为正则运算符的字符进行转义\n",
    "\n",
    "\n",
    "with open(test_file_dir , \"wb+\") as f_test:\n",
    "\n",
    "    f_test.seek(0, 0)  # 指向 切片文件的 首位\n",
    "\n",
    "    row_text = control_chars\n",
    "\n",
    "    row_text_bytes = row_text.encode(encoding)\n",
    "\n",
    "    f_test.write(row_text_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串的 转义\n",
    "s='ABC\\-001'\n",
    "print(s)\n",
    "\n",
    "s = r'ABC\\-001'\n",
    "# 对应的正则表达式字符串不变：\n",
    "print (s) #'ABC\\-001'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgin = \" '!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \"\n",
    "    \n",
    "print('[{0}]'.format(re.escape(orgin)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找 文本中的 所有 不可见字符 \n",
    "\n",
    "import re\n",
    "\n",
    "STX=chr(0x02)\n",
    "SOH=chr(0x01) \n",
    "\n",
    "text='a0'+STX+SOH\n",
    "\n",
    "print(text)\n",
    "\n",
    "reg_illegal = re.compile(\"\\x01\")  # 字节表示 \n",
    "# reg_illegal = re.compile(SOH)  # 字符表示 \n",
    "\n",
    "print(reg_illegal.search(text))\n",
    "\n",
    "control_chars = ''.join(map(chr, list(range(0,32)) + list(range(127,160)))) # 不可见字符的 范围 为 0-32 和 127-160  \n",
    "reg_illegal= re.compile('[%s]' % re.escape(control_chars)) \n",
    "print(reg_illegal.findall(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清除 文本中的 所有 不可见字符 \n",
    "\n",
    "STX=chr(0x02)\n",
    "SOH=chr(0x01) \n",
    "original_json='a0'+STX+SOH\n",
    "\n",
    "def remove_control_chars(s):\n",
    "    control_chars = ''.join(map(chr, list(range(0,32)) + list(range(127,160)))) # 不可见字符的 范围 为 0-32 和 127-160  \n",
    "    \n",
    "    control_chars = re.compile('[%s]' % re.escape(control_chars))\n",
    "\n",
    "    return control_chars.sub('', s)\n",
    "\n",
    "cleaned_json = remove_control_chars(original_json)\n",
    "\n",
    "print(cleaned_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 mapPartitions\n",
    "# 找到 字段 中出现 非法字符 的行 并输出\n",
    "\n",
    "anti_Slash=chr(0x5C) #反斜杠\n",
    "# print(anti_Slash)\n",
    "\n",
    "SOH=chr(0x01)\n",
    "STX=chr(0x02)\n",
    " \n",
    "\n",
    "reg_illegal = re.compile(\"\\x02\") \n",
    "\n",
    "\n",
    "def process_oneslice_find_illegalChar(lines_slice,reg_illegal):\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    for line in lines_slice:\n",
    "    \n",
    "        line_array=line.split(\"\\x01\")\n",
    "        \n",
    "        exist=False\n",
    "        \n",
    "        for field in line_array: # 遍历 一行中的 每一个字段\n",
    "            \n",
    "            if reg_illegal.search(field) !=None:\n",
    "                \n",
    "                res.append( line )\n",
    "                \n",
    "                break\n",
    "          \n",
    "    return res \n",
    "\n",
    "linesByMapPartitions=lines.mapPartitions(lambda lines_slice :process_oneslice_find_illegalChar(lines_slice ,reg_illegal ))\n",
    "\n",
    "# 分区合并 \n",
    "one_slice=linesByMapPartitions.coalesce(1, shuffle=True)\n",
    "one_slice.saveAsTextFile(result_file_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '1', 'B', '2', 'C', '3', 'D', '4', 'E', '5']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python 实现  flatMap\n",
    "\n",
    "def flatten_single_dim(mapped):\n",
    "    for item in mapped:\n",
    "        for subitem in item:\n",
    "            yield subitem\n",
    "            \n",
    "table_a=[['A', '1'], ['B', '2'], ['C', '3'], ['D', '4'],['E','5']]\n",
    "\n",
    "list(flatten_single_dim(table_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用 groupByKey 算子 实现 mapreduce 的 join \n",
    "\n",
    "# table_a=[['A', '1'], ['B', '2'], ['C', '3'], ['D', '4'],['E','5']]\n",
    "# table_b=[['A', 'a'], ['B', 'b'], ['C', 'c'], ['D', 'd']]\n",
    "\n",
    "# table_a = sc.parallelize(table_a,3)\n",
    "# table_b = sc.parallelize(table_b,2)\n",
    "\n",
    "data_dir = '../data_test/'\n",
    "\n",
    "table_a_dir=os.path.join(data_dir, 'table_A')\n",
    "\n",
    "table_b_dir=os.path.join(data_dir, 'table_B')\n",
    "\n",
    "table_dir=os.path.join(data_dir, 'table')\n",
    "\n",
    "sliceNum=2\n",
    "table_a = sc.textFile(table_a_dir,sliceNum)\n",
    "table_b = sc.textFile(table_b_dir,sliceNum)\n",
    "\n",
    "\n",
    "table_a=table_a.map(lambda line : line.split(','))\n",
    "table_b=table_b.map(lambda line : line.split(','))\n",
    "\n",
    "table_a=table_a.map(lambda line: (line[0],line[1:])) # 只能有 两个元素 ，第1个为 Key; 否则后面的 groupByKey() 报错 \n",
    "table_b=table_b.map(lambda line: (line[0],line[1:]))\n",
    "\n",
    "\n",
    "table=table_a.union(table_b) # 合并后 分区 数目 也是 两个 RDD 的分区的和\n",
    "\n",
    "table=table.groupByKey()  # all the *byKey methods(reduce) operate on PairwiseRDDs. In Python it means RDD which contains tuples of length 2. \n",
    "                          # partitionBy requires a PairwiseRDD which in Python is equivalent to RDD of tuples (lists) of length 2 where the first element is a key and the second one is a value.\n",
    "# table.take(10)\n",
    "\n",
    "def flatten_single_dim(mapped):\n",
    "    for item in mapped:\n",
    "        for subitem in item:\n",
    "            yield subitem\n",
    "\n",
    "def process_oneslice(lines_slice,col_num):\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    for line in lines_slice:\n",
    "        \n",
    "        key=line[0]\n",
    "        \n",
    "        values=[]\n",
    "        for col in line[1]:\n",
    "            values.append(col)\n",
    "    \n",
    "        if len(values)== col_num-1: # col 匹配 说明 关联成功\n",
    "            \n",
    "            res.append( [key]+ list(flatten_single_dim(values)) )\n",
    "        \n",
    "    return res \n",
    "\n",
    "col_num=3\n",
    "table=table.mapPartitions(lambda lines_slice : process_oneslice(lines_slice,col_num))\n",
    "\n",
    "# print(table.take(10))\n",
    "\n",
    "table_one_slice=table.map(lambda line : \",\".join(line) ).coalesce(1, shuffle=True) # 输出为 一个切片\n",
    "\n",
    "table_one_slice.saveAsTextFile(table_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 基本 算子 实现 mapreduce 的 join \n",
    "\n",
    "data_dir = '../data_test/'\n",
    "\n",
    "table_a_dir=os.path.join(data_dir, 'table_A')\n",
    "\n",
    "table_b_dir=os.path.join(data_dir, 'table_B')\n",
    "\n",
    "table_dir=os.path.join(data_dir, 'table')\n",
    "\n",
    "sliceNum=2\n",
    "table_a = sc.textFile(table_a_dir,sliceNum)\n",
    "table_b = sc.textFile(table_b_dir,sliceNum)\n",
    "\n",
    "\n",
    "table_a=table_a.map(lambda line : line.split(','))\n",
    "table_b=table_b.map(lambda line : line.split(','))\n",
    "\n",
    "table_a=table_a.map(lambda line: (line[0],line[1:])) # 只能有 两个元素 ，第1个为 Key; 否则后面的 groupByKey() 报错 \n",
    "table_b=table_b.map(lambda line: (line[0],line[1:]))\n",
    "\n",
    "\n",
    "table=table_a.union(table_b) # 合并后 分区 数目 也是 两个 RDD 的分区的和\n",
    "\n",
    "# table.glom().collect() # 输出 各个分区 的元素 列表\n",
    "\n",
    "# [[('1', ['a', '27']), ('2', ['b', '24']), ('3', ['c', '23'])],\n",
    "#  [('4', ['d', '21']), ('5', ['e', '22']), ('6', ['f', '20'])],\n",
    "#  [('1', ['male']), ('2', ['female'])],\n",
    "#  [('4', ['female']), ('5', ['male'])]]\n",
    "\n",
    "\n",
    "table=table.partitionBy(2)  \n",
    "\n",
    "# table.glom().collect() \n",
    "\n",
    "# [[('1', ['a', '27']), ('4', ['d', '21']), ('1', ['male']), ('4', ['female'])],\n",
    "#  [('2', ['b', '24']),\n",
    "#   ('3', ['c', '23']),\n",
    "#   ('5', ['e', '22']),\n",
    "#   ('6', ['f', '20']),\n",
    "#   ('2', ['female']),\n",
    "#   ('5', ['male'])]]\n",
    "\n",
    "def process_oneslice(one_slice,col_num):\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    hash_table={}\n",
    "    \n",
    "    for line in one_slice:\n",
    "        \n",
    "        key=line[0]\n",
    "        value=line[1]\n",
    "        \n",
    "        if  key not in hash_table:\n",
    "            hash_table[key]=value\n",
    "        \n",
    "        else:\n",
    "            hash_table[key]= hash_table[key]+value\n",
    "    \n",
    "    for  key, value in hash_table.items():\n",
    "        \n",
    "        if len(value) == col_num: # 这一行的 col 个数 匹配 说明 关联成功\n",
    "            \n",
    "            res.append([key]+value)\n",
    "    \n",
    "    return res \n",
    "        \n",
    "\n",
    "col_num=3 # 最终表 除了 Key 之外 应该有 3 个列（字段）\n",
    "table=table.mapPartitions(lambda one_slice : process_oneslice(one_slice,col_num))\n",
    "\n",
    "# table.glom().collect() \n",
    "\n",
    "table_one_slice=table.map(lambda line : \",\".join(line) ).coalesce(1, shuffle=True) # 输出为 一个切片\n",
    "\n",
    "table_one_slice.saveAsTextFile(table_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 基本 算子 实现 hash join \n",
    "\n",
    "data_dir = '../data_test/'\n",
    "\n",
    "table_a_dir=os.path.join(data_dir, 'table_A')\n",
    "\n",
    "table_b_dir=os.path.join(data_dir, 'table_B')\n",
    "\n",
    "table_dir=os.path.join(data_dir, 'table')\n",
    "\n",
    "\n",
    "sliceNum = 2\n",
    "table_a = sc.textFile(table_a_dir, sliceNum)\n",
    "table_b = sc.textFile(table_b_dir, sliceNum)\n",
    "\n",
    "table_a = table_a.map(lambda line: line.split(',')) # 大表\n",
    "table_b = table_b.map(lambda line: line.split(',')) # 小表\n",
    "\n",
    "table_a = table_a.map(lambda line: (line[0], line[1:]))  # 只能有 两个元素 ，第1个为 Key; 否则后面的 groupByKey() 报错\n",
    "table_b = table_b.map(lambda line: (line[0], line[1:]))\n",
    "\n",
    "table_b=table_b.collect() #[('1', ['male']), ('2', ['female']), ('4', ['female']), ('5', ['male'])]\n",
    "\n",
    "hash_table_b={}\n",
    "\n",
    "for line in table_b:\n",
    "    hash_table_b[line[0]]=line[1][0]\n",
    "\n",
    "# 把小表 作为 广播变量 分发到各个 计算节点上\n",
    "broadcast_table_b = sc.broadcast(hash_table_b) # SPARK-5063: RDD 不能被广播\n",
    "\n",
    "\n",
    "def process_oneslice(big_table_slice):\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    for line in big_table_slice:\n",
    "        \n",
    "        key=line[0]\n",
    "        \n",
    "        values=line[1]\n",
    "        \n",
    "        if key in hash_table_b:\n",
    "            \n",
    "            res.append( [key]+[hash_table_b[key]] + values )\n",
    "        \n",
    "    return res \n",
    "\n",
    "table=table_a.mapPartitions(lambda big_table_slice : process_oneslice(big_table_slice))\n",
    "\n",
    "# table.collect()\n",
    "\n",
    "table_one_slice=table.map(lambda line : \",\".join(line) ).coalesce(1, shuffle=True) # 输出为 一个切片\n",
    "\n",
    "table_one_slice.saveAsTextFile(table_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
